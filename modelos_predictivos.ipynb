{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajo Práctico 1: Modelos Predictivos en SciKit-Learn\n",
    "\n",
    "- Paloma Monzon Borioli\n",
    "- Camila Belen Vivo\n",
    "- Martin Berestovoy\n",
    "\n",
    "https://github.com/IgnacioPardo/Tecnologias_Exponenciales_2023/blob/main/Consigna_ModelosPredictivos.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avanzado Tecnologías Exponenciales 2023\n",
    "\n",
    "#### Consigna\n",
    "\n",
    "En grupos de 2 o 3 personas, realizar los siguientes ejercicios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigar y seleccionar un dataset que cumpla con tener entre 1000 y 10.000 muestras, 5 o más atributos numéricos y al menos un atributo categórico (Recomendación: seleccionar un atributo a predecir binario). De encontrar algún dataset sin atributos categóricos, ¿Como se podría generar uno binario a partir de los atributos numéricos? Se recomienda utilizar Kaggle para la búsqueda del dataset. Antes de avanzar con el trabajo práctico, corroborar el dataset en clase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, RidgeCV, RidgeClassifierCV, LassoCV\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el dataset\n",
    "df = pd.read_csv('athletes.csv')\n",
    "\n",
    "# Eliminamos las filas con datos nulos\n",
    "df = df.dropna()\n",
    "\n",
    "# Eliminamos las columnas innecesarias\n",
    "columns_to_drop = ['Games', 'Name', 'Season', 'City', 'Event', 'NOC', 'ID']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Filtramos el dataset para que solo tenga 10000 filas\n",
    "df = df.sample(n=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 2. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar un análisis exploratorio de los datos. Se recomienda utilizar gráficos para visualizar la distribución de los datos y la correlación entre los atributos. Se recomienda utilizar la librería `seaborn` para realizar los gráficos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desactivamos advertencias que son bastante molestas\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Distribucion de variables numericas\n",
    "\n",
    "# Hacemos el grafico y definimos la separacion de los parametros con el bins\n",
    "sns.histplot(data=df, x='Age', bins=50)\n",
    "# Mostramos el grafico\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df, x='Height', bins=50)\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df, x='Weight', bins=50)\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df, x='Year', bins=50)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Distribucion de variables categoricas\n",
    "\n",
    "\n",
    "# Configuramos el tamaño de la figura\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.countplot(data=df, x='Sport')\n",
    "# Definimos la rotacion de las palabras para que esten en vertical, mas chicas y en el centro asi son legibles\n",
    "plt.xticks(rotation=90, fontsize=20, ha='center')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.countplot(data=df, x='Medal')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.countplot(data=df, x='Sex')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(50, 15))\n",
    "sns.countplot(data=df, x='Team')\n",
    "plt.xticks(rotation=90, fontsize=10, ha='center')\n",
    "plt.show()\n",
    "# Chona, te juramos que no se puede hacer mas legible el grafico por la abrupta cantidad de paises que tiene, sabe disculparnos :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resultado del análisis exploratorio, seleccionar un atributo categórico y un atributo numérico para realizar un modelo de clasificación. Se recomienda utilizar la función `LabelEncoder` de SciKit-Learn para convertir el atributo categórico a numérico.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos como atributo numerico la edad y como atributo categorico la medalla\n",
    "\n",
    "# Creamos un diccionario de mapeo de valores\n",
    "medal_mapping = {\"Gold\": 1, \"Silver\": 2, \"Bronze\": 3}\n",
    "# Aplicamos el mapeo a la columna \"Medal\"\n",
    "df['Medal'] = df['Medal'].map(medal_mapping)\n",
    "\n",
    "# Aca hacemos un encoding de las columnas que son categoricas\n",
    "leTeam = preprocessing.LabelEncoder()\n",
    "leSport = preprocessing.LabelEncoder()\n",
    "\n",
    "leTeam.fit(df['Team'])\n",
    "leSport.fit(df['Sport'])\n",
    "\n",
    "df['Team'] = leTeam.transform(df['Team'])\n",
    "df['Sport'] = leSport.transform(df['Sport'])\n",
    "\n",
    "# Hacemos una columna booleana para ver si es hombre o no (mujer)\n",
    "df['IsMale'] = df['Sex'].replace({'M': True, 'F': False})\n",
    "df = df.drop(columns='Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 4. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar una partición de los datos en conjuntos de entrenamiento y test. La proporción con la cual hacen esta partición es libre. Se recomienda utilizar la función `train_test_split` de SciKit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la particion de los datos en entrenamiento y testeo\n",
    "\n",
    "# Dividimos el conjunto de datos en características (X) y la variable objetivo (y)\n",
    "X_num = df.drop(columns=['Age'])  # Eliminamos la columna 'Age' como nuestra variable objetivo ya que en base a las otras columnas queremos predecir la edad\n",
    "y_num = df['Age']\n",
    "\n",
    "X_cat = df.drop(columns=['Medal'])  # Eliminamos la columna 'Medal' como nuestra variable objetivo ya que en base a las otras columnas queremos predecir la medalla\n",
    "y_cat = df['Medal']\n",
    "\n",
    "# Realizamos la particion de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_num, X_test_num, y_train_num, y_test_num = train_test_split(X_num, y_num, test_size=0.2, random_state=42)\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X_cat, y_cat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 5. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el atributo numérico a predecir seleccionado:\n",
    "\n",
    "- Realizar un modelo de regresión lineal utilizando la clase `LinearRegression` de SciKit-Learn.\n",
    "- Realizar un modelo de Árbol de Decisión utilizando la clase `DecisionTreeRegressor` de SciKit-Learn. Seleccionar hiperparámetros que les parezca mejoren el modelo.\n",
    "\n",
    "Responder:\n",
    "¿Que formas tienen de evaluar los resultados de cada árbol de decisión? ¿Como eligen \"el mejor árbol\"? ¿Como se comparan los resultados de los modelos de regresión lineal y de árbol de decisión?\n",
    "\n",
    "Sugerencia: Aprovechar los conceptos de validación y de validación cruzada para evaluar los modelos. Pueden utilizar la función `cross_val_score` de SciKit-Learn para evaluar los modelos.\n",
    "\n",
    "Se recomienda utilizar la función `cross_val_score` de SciKit-Learn para evaluar los modelos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la cantidad de folds\n",
    "k_folds = 5\n",
    "\n",
    "# Evaluamos la Regresion Lineal\n",
    "linear_regresion_scores = cross_val_score(LinearRegression(), X_num, y_num, cv = k_folds, scoring = make_scorer(mean_squared_error))\n",
    "\n",
    "# Evaluamos el Arbol de Decision sin afinar hiperparametros\n",
    "decision_tree_scores = cross_val_score(DecisionTreeRegressor(), X_num, y_num, cv = k_folds, scoring = make_scorer(mean_squared_error))\n",
    "\n",
    "# Calculamos la media y desviacion estandar de los puntajes de MSE para los modelos\n",
    "print(\"Regresion Lineal MSE:\", round(linear_regresion_scores.mean(), 2)) # Ponemos ese round para que no salga con tantos decimales\n",
    "print(\"Arbol de Decision MSE:\", round(decision_tree_scores.mean(), 2))\n",
    "\n",
    "# Cuanto mas chico sea el MSE, mejor es el modelo.\n",
    "if(linear_regresion_scores.mean() < decision_tree_scores.mean()):\n",
    "    print(\"El modelo de Regresion Lineal es mejor que el modelo de Arbol de Decision\")\n",
    "else:\n",
    "    print(\"El modelo de Arbol de Decision es mejor que el modelo de Regresion Lineal\")\n",
    "\n",
    "# Afinamos hiperparametros del Arbol de Decision\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Realizamos la busqueda de hiperparametros con GridSearchCV y 5 folds de validacion cruzada (k_folds) y scoring de MSE (mean_squared_error) para el Arbol de Decision sin afinar hiperparametros (DecisionTreeRegressor()) y los hiperparametros definidos en el diccionario (param_grid)\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(), param_grid, cv = k_folds, scoring = make_scorer(mean_squared_error))\n",
    "grid_search.fit(X_num, y_num)\n",
    "\n",
    "# Evaluamos el Arbol de Decision con hiperparametros optimizados\n",
    "dt_optimized = DecisionTreeRegressor(**grid_search.best_params_)\n",
    "dt_optimized_scores = cross_val_score(dt_optimized, X_num, y_num, cv = k_folds, scoring = make_scorer(mean_squared_error))\n",
    "\n",
    "# Calculamos la media y desviacion estandar de los puntajes de MSE para el Arbol de Decision optimizado\n",
    "print(\"Arbol de Decision optimizado MSE:\", round(dt_optimized_scores.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respondemos a las preguntas:\n",
    "\n",
    "##### ¿Que formas tienen de evaluar los resultados de cada árbol de decisión?\n",
    "Los modelos se evaluan con un \"score\", es decir que se pone a prueba el modelo con un conjunto de datos de testeo y se obtiene un valor que indica que tan bien se comporta el modelo con esos datos.\n",
    "##### ¿Como eligen \"el mejor árbol\"?\n",
    "El mejor arbol es el que tiene el mejor score, es decir el que mejor se comporta con los datos de testeo. \n",
    "##### ¿Como se comparan los resultados de los modelos de regresión lineal y de árbol de decisión?\n",
    "Se comparan viendo el score, el que tenga un score mas alto es el que mejor se comporta con los datos de testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 6. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el atributo categórico a predecir seleccionado\n",
    "\n",
    "- Realizar un modelo de clasificación utilizando la clase `LogisticRegression` de SciKit-Learn.\n",
    "- Realizar un modelo de clasificación utilizando la clase `DecisionTreeClassifier` de SciKit-Learn.\n",
    "\n",
    "Responder las mismas preguntas que en el punto 5 para este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de Regresion Logistica\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Mostramos el score del modelo de Regresion Logistica\n",
    "print(\"Score del modelo de Regresion Logistica:\")\n",
    "display(cross_val_score(logistic_regression_model, X_cat, y_cat, cv=k_folds))\n",
    "\n",
    "# Modelo de Arbol de Decision\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "print(\"Score del modelo de Arbol de Decision:\")\n",
    "display(cross_val_score(decision_tree_model, X_cat, y_cat, cv=k_folds))\n",
    "\n",
    "# Debido a que el modelo de Arbol de Decision tiene un score mas alto que el modelo de Regresion Logistica, elegimos el modelo de Arbol de Decision\n",
    "\n",
    "# Definimos los hiperparametros para el modelo de Arbol de Decision\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Realizamos la busqueda de hiperparametros con GridSearchCV y 5 folds de validacion cruzada (k_folds) y scoring de MSE (mean_squared_error) para el Arbol de Decision sin afinar hiperparametros (DecisionTreeRegressor()) y los hiperparametros definidos en el diccionario (param_grid)\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv = k_folds, scoring = make_scorer(accuracy_score))\n",
    "grid_search.fit(X_cat, y_cat)\n",
    "\n",
    "# Evaluamos el Arbol de Decision con hiperparametros optimizados\n",
    "dt_optimized = DecisionTreeClassifier(**grid_search.best_params_)\n",
    "dt_optimized_scores = cross_val_score(dt_optimized, X_cat, y_cat, cv = k_folds, scoring = make_scorer(accuracy_score))\n",
    "\n",
    "# Calculamos la media y desviacion estandar de los puntajes de MSE para el Arbol de Decision optimizado\n",
    "print(\"Arbol de Decision optimizado MSE:\", round(dt_optimized_scores.mean(), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respondiendo a las preguntas:\n",
    "\n",
    "##### ¿Que formas tienen de evaluar los resultados de cada árbol de decisión?\n",
    "Las formas mas usadas que son \"Logistic Regression\" y \"Decision Tree Classifier\", usan la \"Acuracy\" para evaluar los resultados con un \"Score\".\n",
    "##### ¿Como eligen \"el mejor árbol\"?\n",
    "El mejor arbol es el que tiene el mejor score, es decir el que mejor se comporta con los datos de testeo. (Igual que en el punto 5)\n",
    "##### ¿Como se comparan los resultados de los modelos de regresión lineal y de árbol de decisión?\n",
    "Al igual que en el punto 5, se comparan viendo el score, el que tenga un score mas alto es el que mejor se comporta con los datos de testeo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 7. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar distintos métodos de validación cruzada. ¿Que ventajas y desventajas tiene cada uno?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 8. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribir una conclusión sobre el trabajo realizado.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigar los métodos GridSearch y RandomSearch para la búsqueda de hiperparámetros. Utilizarlos para encontrar los mejores hiperparámetros para los modelos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ya sea el atributo categórico como para el numérico, elegir otro modelo de clasificación o regresión que no haya sido utilizado anteriormente. Entrenar el modelo y comparar los resultados con los obtenidos anteriormente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrega y Bibliografia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Formato de entrega\n",
    "\n",
    "El trabajo práctico se debe realizar en un notebook de Jupyter. El notebook debe estar subido a un repositorio de GitHub. El link al repositorio debe ser completado en el siguiente [Google Form]().\n",
    "\n",
    "\n",
    "#### Fecha de entrega\n",
    "\n",
    "El trabajo práctico se debe entregar hasta el 17/09/2023 a las 23:59hs.\n",
    "\n",
    "#### Bibliografía\n",
    "\n",
    "- [SciKit-Learn](https://scikit-learn.org/stable/)\n",
    "- [Seaborn](https://seaborn.pydata.org/)\n",
    "- [Kaggle](https://www.kaggle.com/)\n",
    "- [Cross Validation](https://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
