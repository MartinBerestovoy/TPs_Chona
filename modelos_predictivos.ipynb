{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajo Práctico 1: Modelos Predictivos en SciKit-Learn\n",
    "\n",
    "- Paloma Monzon Borioli\n",
    "- Camila Belen Vivo\n",
    "- Martin Berestovoy\n",
    "\n",
    "https://github.com/IgnacioPardo/Tecnologias_Exponenciales_2023/blob/main/Consigna_ModelosPredictivos.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avanzado Tecnologías Exponenciales 2023\n",
    "\n",
    "#### Consigna\n",
    "\n",
    "En grupos de 2 o 3 personas, realizar los siguientes ejercicios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigar y seleccionar un dataset que cumpla con tener entre 1000 y 10.000 muestras, 5 o más atributos numéricos y al menos un atributo categórico (Recomendación: seleccionar un atributo a predecir binario). De encontrar algún dataset sin atributos categóricos, ¿Como se podría generar uno binario a partir de los atributos numéricos? Se recomienda utilizar Kaggle para la búsqueda del dataset. Antes de avanzar con el trabajo práctico, corroborar el dataset en clase.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, RidgeCV, RidgeClassifierCV, LassoCV\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el dataset\n",
    "df = pd.read_csv('athletes.csv')\n",
    "\n",
    "# Eliminamos las filas con datos nulos\n",
    "df = df.dropna()\n",
    "\n",
    "# Eliminamos las columnas innecesarias\n",
    "columns_to_drop = ['Games', 'Name', 'Season', 'City', 'Event', 'NOC', 'ID']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Filtramos el dataset para que solo tenga 10000 filas\n",
    "df = df.sample(n=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 2. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar un análisis exploratorio de los datos. Se recomienda utilizar gráficos para visualizar la distribución de los datos y la correlación entre los atributos. Se recomienda utilizar la librería `seaborn` para realizar los gráficos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desactivamos advertencias que son bastante molestas\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Distribucion de variables numericas\n",
    "\n",
    "# Hacemos el grafico y definimos la separacion de los parametros con el bins\n",
    "sns.histplot(data=df, x='Age', bins=50)\n",
    "# Mostramos el grafico\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df, x='Height', bins=50)\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df, x='Weight', bins=50)\n",
    "plt.show()\n",
    "\n",
    "sns.histplot(data=df, x='Year', bins=50)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Distribucion de variables categoricas\n",
    "\n",
    "\n",
    "# Configuramos el tamaño de la figura\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.countplot(data=df, x='Sport')\n",
    "# Definimos la rotacion de las palabras para que esten en vertical, mas chicas y en el centro asi son legibles\n",
    "plt.xticks(rotation=90, fontsize=20, ha='center')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.countplot(data=df, x='Medal')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.countplot(data=df, x='Sex')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(50, 15))\n",
    "sns.countplot(data=df, x='Team')\n",
    "plt.xticks(rotation=90, fontsize=10, ha='center')\n",
    "plt.show()\n",
    "# Chona, te juramos que no se puede hacer mas legible el grafico por la abrupta cantidad de paises que tiene, sabe disculparnos :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resultado del análisis exploratorio, seleccionar un atributo categórico y un atributo numérico para realizar un modelo de clasificación. Se recomienda utilizar la función `LabelEncoder` de SciKit-Learn para convertir el atributo categórico a numérico.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos como atributo numerico la edad y como atributo categorico la medalla\n",
    "\n",
    "# Creamos un diccionario de mapeo de valores\n",
    "medal_mapping = {\"Gold\": 1, \"Silver\": 2, \"Bronze\": 3}\n",
    "# Aplicamos el mapeo a la columna \"Medal\"\n",
    "df['Medal'] = df['Medal'].map(medal_mapping)\n",
    "\n",
    "# Aca hacemos un encoding de las columnas que son categoricas\n",
    "leTeam = preprocessing.LabelEncoder()\n",
    "leSport = preprocessing.LabelEncoder()\n",
    "\n",
    "leTeam.fit(df['Team'])\n",
    "leSport.fit(df['Sport'])\n",
    "\n",
    "df['Team'] = leTeam.transform(df['Team'])\n",
    "df['Sport'] = leSport.transform(df['Sport'])\n",
    "\n",
    "# Hacemos una columna booleana para ver si es hombre o no (mujer)\n",
    "df['IsMale'] = df['Sex'].replace({'M': True, 'F': False})\n",
    "df = df.drop(columns='Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 4. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar una partición de los datos en conjuntos de entrenamiento y test. La proporción con la cual hacen esta partición es libre. Se recomienda utilizar la función `train_test_split` de SciKit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos la particion de los datos en entrenamiento y testeo\n",
    "\n",
    "# Dividimos el conjunto de datos en características (X) y la variable objetivo (y)\n",
    "X_num = df.drop(columns=['Age'])  # Eliminamos la columna 'Age' como nuestra variable objetivo ya que en base a las otras columnas queremos predecir la edad\n",
    "y_num = df['Age']\n",
    "\n",
    "X_cat = df.drop(columns=['Medal'])  # Eliminamos la columna 'Medal' como nuestra variable objetivo ya que en base a las otras columnas queremos predecir la medalla\n",
    "y_cat = df['Medal']\n",
    "\n",
    "# Realizamos la particion de los datos en conjuntos de entrenamiento y prueba\n",
    "X_train_num, X_test_num, y_train_num, y_test_num = train_test_split(X_num, y_num, test_size=0.2, random_state=42)\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X_cat, y_cat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 5. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el atributo numérico a predecir seleccionado:\n",
    "\n",
    "- Realizar un modelo de regresión lineal utilizando la clase `LinearRegression` de SciKit-Learn.\n",
    "- Realizar un modelo de Árbol de Decisión utilizando la clase `DecisionTreeRegressor` de SciKit-Learn. Seleccionar hiperparámetros que les parezca mejoren el modelo.\n",
    "\n",
    "Responder:\n",
    "¿Que formas tienen de evaluar los resultados de cada árbol de decisión? ¿Como eligen \"el mejor árbol\"? ¿Como se comparan los resultados de los modelos de regresión lineal y de árbol de decisión?\n",
    "\n",
    "Sugerencia: Aprovechar los conceptos de validación y de validación cruzada para evaluar los modelos. Pueden utilizar la función `cross_val_score` de SciKit-Learn para evaluar los modelos.\n",
    "\n",
    "Se recomienda utilizar la función `cross_val_score` de SciKit-Learn para evaluar los modelos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la cantidad de folds\n",
    "k_folds = 5\n",
    "\n",
    "# Evaluamos la Regresion Lineal\n",
    "linear_regresion_scores = cross_val_score(LinearRegression(), X_num, y_num, cv = k_folds, scoring = make_scorer(mean_squared_error))\n",
    "\n",
    "# Evaluamos el Arbol de Decision sin afinar hiperparametros\n",
    "decision_tree_scores = cross_val_score(DecisionTreeRegressor(), X_num, y_num, cv = k_folds, scoring = make_scorer(mean_squared_error))\n",
    "\n",
    "# Calculamos la media y desviacion estandar de los puntajes de MSE para los modelos\n",
    "print(\"Regresion Lineal MSE:\", round(linear_regresion_scores.mean(), 2)) # Ponemos ese round para que no salga con tantos decimales\n",
    "print(\"Arbol de Decision MSE:\", round(decision_tree_scores.mean(), 2))\n",
    "\n",
    "# Cuanto mas chico sea el MSE, mejor es el modelo.\n",
    "if(linear_regresion_scores.mean() < decision_tree_scores.mean()):\n",
    "    print(\"El modelo de Regresion Lineal es mejor que el modelo de Arbol de Decision\")\n",
    "else:\n",
    "    print(\"El modelo de Arbol de Decision es mejor que el modelo de Regresion Lineal\")\n",
    "\n",
    "# Afinamos hiperparametros del Arbol de Decision\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Realizamos la busqueda de hiperparametros con GridSearchCV y 5 folds de validacion cruzada (k_folds) y scoring de MSE (mean_squared_error) para el Arbol de Decision sin afinar hiperparametros (DecisionTreeRegressor()) y los hiperparametros definidos en el diccionario (param_grid)\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(), param_grid, cv = k_folds, scoring = make_scorer(mean_squared_error))\n",
    "grid_search.fit(X_num, y_num)\n",
    "\n",
    "# Evaluamos el Arbol de Decision con hiperparametros optimizados\n",
    "dt_optimized = DecisionTreeRegressor(**grid_search.best_params_)\n",
    "dt_optimized_scores = cross_val_score(dt_optimized, X_num, y_num, cv = k_folds, scoring = make_scorer(mean_squared_error))\n",
    "\n",
    "# Calculamos la media y desviacion estandar de los puntajes de MSE para el Arbol de Decision optimizado\n",
    "print(\"Arbol de Decision optimizado MSE:\", round(dt_optimized_scores.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respondemos a las preguntas:\n",
    "\n",
    "##### ¿Que formas tienen de evaluar los resultados de cada árbol de decisión?\n",
    "Los modelos se evaluan con un \"score\", es decir que se pone a prueba el modelo con un conjunto de datos de testeo y se obtiene un valor que indica que tan bien se comporta el modelo con esos datos.\n",
    "##### ¿Como eligen \"el mejor árbol\"?\n",
    "El criterio para elegir el mejor árbol se basa en la puntuación obtenida. Es decir, el que tiene el mejor score. \n",
    "##### ¿Como se comparan los resultados de los modelos de regresión lineal y de árbol de decisión?\n",
    "Se comparan viendo el score, el que tenga un score mas alto es el que mejor se comporta con los datos de testeo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 6. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el atributo categórico a predecir seleccionado\n",
    "\n",
    "- Realizar un modelo de clasificación utilizando la clase `LogisticRegression` de SciKit-Learn.\n",
    "- Realizar un modelo de clasificación utilizando la clase `DecisionTreeClassifier` de SciKit-Learn.\n",
    "\n",
    "Responder las mismas preguntas que en el punto 5 para este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de Regresion Logistica\n",
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Mostramos el score del modelo de Regresion Logistica\n",
    "print(\"Score del modelo de Regresion Logistica:\")\n",
    "display(cross_val_score(logistic_regression_model, X_cat, y_cat, cv=k_folds))\n",
    "\n",
    "# Modelo de Arbol de Decision\n",
    "decision_tree_model = DecisionTreeClassifier()\n",
    "print(\"Score del modelo de Arbol de Decision:\")\n",
    "display(cross_val_score(decision_tree_model, X_cat, y_cat, cv=k_folds))\n",
    "\n",
    "# Debido a que el modelo de Arbol de Decision tiene un score mas alto que el modelo de Regresion Logistica, elegimos el modelo de Arbol de Decision\n",
    "\n",
    "# Definimos los hiperparametros para el modelo de Arbol de Decision\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Realizamos la busqueda de hiperparametros con GridSearchCV y 5 folds de validacion cruzada (k_folds) y scoring de MSE (mean_squared_error) para el Arbol de Decision sin afinar hiperparametros (DecisionTreeRegressor()) y los hiperparametros definidos en el diccionario (param_grid)\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv = k_folds, scoring = make_scorer(accuracy_score))\n",
    "grid_search.fit(X_cat, y_cat)\n",
    "\n",
    "# Evaluamos el Arbol de Decision con hiperparametros optimizados\n",
    "dt_optimized = DecisionTreeClassifier(**grid_search.best_params_)\n",
    "dt_optimized_scores = cross_val_score(dt_optimized, X_cat, y_cat, cv = k_folds, scoring = make_scorer(accuracy_score))\n",
    "\n",
    "# Calculamos la media y desviacion estandar de los puntajes de MSE para el Arbol de Decision optimizado\n",
    "print(\"Arbol de Decision optimizado MSE:\", round(dt_optimized_scores.mean(), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Respondiendo a las preguntas:\n",
    "\n",
    "##### ¿Que formas tienen de evaluar los resultados de cada árbol de decisión?\n",
    "Las formas mas usadas que son \"Logistic Regression\" y \"Decision Tree Classifier\", las cuales usan la \"Acuracy\"(exactitud) para medir cuán bien funcionan, devolviendonos un \"Score\" que lo refleja.\n",
    "##### ¿Como eligen \"el mejor árbol\"?\n",
    "Para determinar cuál de estos modelos es el mejor arbol, simplemente comparan las puntuaciones de \"Score\". El modelo que obtiene la puntuación más alta, es decir, el que mejor se adapta a los datos de test, se considera como el mejor.(Igual que en el punto 5)\n",
    "##### ¿Como se comparan los resultados de los modelos de regresión lineal y de árbol de decisión?\n",
    "Al igual que en el punto 5, se comparan viendo el score, el que tenga un score mas alto es el que mejor se comporta con los datos de testeo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 7. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparar distintos métodos de validación cruzada. ¿Que ventajas y desventajas tiene cada uno?\n",
    "\n",
    "Validación Cruzada K-Fold:\n",
    "La validación cruzada K-Fold es una técnica utilizada para evaluar el rendimiento de un modelo de machine learning. divide los datos en “k” partes que tienen aproximadamente el mismo tamaño. El modelo se entrena y evalúa K veces. Uno se utiliza como modelo de prueba mientras que los demás se usan como entrenamiento. Cuando se terminan de hacer las K iteraciones se calcula el promedio de resultados y se estima el rendimiento del modelo.\n",
    "Las ventajas que tiene este modelo son que te permite ver el rendimiento del modelo y mientras más iteraciones hagas más confiable va a serla evaluación del modelo. Además va a usar todos los datos ya sea para entrenamiento como para validación. Sin embargo no es recomendable usarlo con datos de tamales muy grande ya que le costaría mucho más a la computadora. Además este no puede ser usado en para datos desbalanceados o patrones temporales.\n",
    "\n",
    "Leave-One-Out (LOO):\n",
    "La validación cruzada Leave-One-Out (LOO) es una técnica de validación cruzada donde se utiliza un solo dato como conjunto de prueba y el resto de los datos como conjunto de entrenamiento en cada iteración. Para un conjunto de datos de tamaño X, se utilizan X iteraciones. Por iteración se usa únicamente un dato es usado como prueba  mientras al resto se los usa de entrenamiento. Cada iteración devuelve el error cuadrático medio y con estos resultados se promedian dando una estimación del rendimiento del modelo.\n",
    "Las ventajas que tiene es que puede usar todos los datos en cada iteración, además hace una evaluación cuidadosa y extensa del rendimiento del modelo. Es muy útil con datos pequeños ya que te permite aprovechar todos los datos. Sin embargo, esto también le genera un costo alto a la computadora porque se tiene que repetir N veces y no se lo recomienda para grandes conjuntos de datos por la cantidad de iteraciones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ej 8. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Escribir una conclusión sobre el trabajo realizado.\n",
    "\n",
    "Este trabajo nos ayudó a entender mejor cómo funcionan los diferentes modelos predictivos y el machine learning en general. Gracias a esto, ahora estamos mejor preparados para crear nuestros propios modelos. Este TP nos dio una base sólida, pero sentimos que es eso, una base, para mejorar nuestra confianza y para seguir explorando, ya que en caso de por ejemplo ser nuesro rol en proyecto necesitariamos herramientas mas complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigar los métodos GridSearch y RandomSearch para la búsqueda de hiperparámetros. Utilizarlos para encontrar los mejores hiperparámetros para los modelos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En el bonus 2 y en el ej.6 usamos GridSearch y aca tenemos una vercion del bonus dos usando RandomSeach\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "# Definimos X e Y\n",
    "X = df.drop({'weight', 'sex'}, axis=1)\n",
    "y = df['sex']\n",
    "\n",
    "# Dividimos los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalamos los datos\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Definimos los hiperparámetros a explorar con RandomizedSearchCV\n",
    "params = {'n_neighbors': np.arange(1, 22),\n",
    "          'weights': ['uniform', 'distance'],\n",
    "          'p': [1, 2]}\n",
    "\n",
    "# Creamos el objeto RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(KNeighborsClassifier(), params, n_iter=10, cv=5, random_state=42)\n",
    "\n",
    "# Ajustamos el modelo con búsqueda aleatoria\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtenemos el mejor modelo y sus hiperparámetros\n",
    "best_knn = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Predecimos con el mejor modelo\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Evaluamos el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Precisión del modelo KNN con', best_params, ':', accuracy)\n",
    "\n",
    "# Cross Validation para mejorar\n",
    "cv_scores = cross_val_score(best_knn, X, y, cv=10)\n",
    "print('Puntuaciones de Cross Validation:', cv_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ya sea el atributo categórico como para el numérico, elegir otro modelo de clasificación o regresión que no haya sido utilizado anteriormente. Entrenar el modelo y comparar los resultados con los obtenidos anteriormente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Definimos X e Y\n",
    "x= df.drop({'weight', 'sex',})\n",
    "y : pd.Series = df['sex']\n",
    "\n",
    "#Dividimos los datos de train/test\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Escalamos\n",
    "scalter : StandardScaler = MinMaxScaler()\n",
    "X_train = scalter.fit_transform(X_train)\n",
    "X_test = scalter.fit_transform(X_test)\n",
    "\n",
    "#Usamos GridSerch\n",
    "params1 : dict = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 21]}\n",
    "grid_search : GridSearchCV(KNeighborsClassifier(), params1, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_n_neighborns : int= grid_search.best_params_('n_neighbors')\n",
    "\n",
    "#Creamos l mejor modelo segun lo que nos dio\n",
    "knn : KNeighborsClassifier = KNeighborsClassifier(n_neighbors=best_n_neighborns)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predecimos\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Evaluamos \n",
    "accuracy : float = accuracy_score(y_test, y_pred)\n",
    "print('Precision del modelo knn con', best_n_neighborns, 'neighbors:',accuracy)\n",
    "\n",
    "#Cross Validation para mejorar\n",
    "cv_scores = cross_val_score(knn, x, y, cv=10)\n",
    "print('Puntuacionde CrossValidation', cv_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
